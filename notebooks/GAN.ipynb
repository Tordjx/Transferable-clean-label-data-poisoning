{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import sys\n",
    "from lightning.pytorch.callbacks import StochasticWeightAveraging\n",
    "import glob\n",
    "import lightning as L\n",
    "sys.path.insert(0, \"/home/tordjx/DATA_DIR/config/projects/TRANSFERABLECLEANDATAPOISONING/lib/python/\")\n",
    "from customlib.dataloaders import CustomDataset\n",
    "data_dir = '/home/tordjx/DATA_DIR/managed_folders/TRANSFERABLECLEANDATAPOISONING/LMc8Smw6/'\n",
    "import timm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "import torchmetrics\n",
    "import torch\n",
    "torch.manual_seed(0)\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "train_dataset = CustomDataset(data_dir, train=True, poison_dir = \"/home/tordjx/DATA_DIR/managed_folders/TRANSFERABLECLEANDATAPOISONING/BqfvFGr8\")\n",
    "test_dataset = CustomDataset(data_dir, train=False)\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers = 19  )\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers = 19)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(L.LightningModule):\n",
    "    def __init__(self,encoders, intermediate_size = 128, nclasses= 43):\n",
    "        super().__init__()\n",
    "        feature_sizes = [(encoder(torch.rand(2,3,128,128))).shape[-1] for encoder in encoders ] \n",
    "        feature_sizes = list(set(feature_sizes))\n",
    "        self.feature_sizes_dict = dict(zip(feature_sizes , [i for i in range(len(feature_sizes))]))\n",
    "        self.intermediate_layers = nn.ModuleList([nn.Linear(f_size, intermediate_size) for f_size in feature_sizes])\n",
    "        self.classif_head = nn.Linear(intermediate_size, nclasses)\n",
    "        self.fake_detectors = nn.Linear(intermediate_size, 2)\n",
    "    def forward(self,x) : \n",
    "        x = nn.functional.relu(self.intermediate_layers[self.feature_sizes_dict[x.shape[-1]]](x))\n",
    "        x = nn.functional.relu(self.classif_head(x))\n",
    "        return x\n",
    "    def detect_fake(self,x) :\n",
    "        x = nn.functional.relu(self.intermediate_layers[self.feature_sizes_dict[x.shape[-1]]](x))\n",
    "        x = nn.functional.relu(self.fake_detectors(x))\n",
    "        return x\n",
    "class Discriminator(L.LightningModule):\n",
    "    def __init__(self,encoder_names ,decoder_size = 128, nclasses=43, encoder_freeze = True):\n",
    "        super().__init__()\n",
    "        self.encoders = nn.ModuleList([\n",
    "            timm.create_model(encoder_name, num_classes = 0 , pretrained = True) for encoder_name in encoder_names\n",
    "        ])\n",
    "        if encoder_freeze : \n",
    "            for param in self.encoders.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.decoder  = Decoder(self.encoders)\n",
    "    def forward(self,x):\n",
    "        embeddings = [encoder(x) for encoder in self.encoders]\n",
    "        return torch.stack([self.decoder(emb) for emb in embeddings]),torch.stack([self.decoder.detect_fake(emb) for emb in embeddings])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 12:59:17.731726: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-19 12:59:17.732996: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-19 12:59:17.750361: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-19 12:59:17.750377: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-19 12:59:17.750390: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-19 12:59:17.754494: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-19 12:59:18.168248: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from monai.networks.nets import UNet,BasicUNetPlusPlus\n",
    "class Generator(L.LightningModule):\n",
    "    def __init__(self) : \n",
    "        super().__init__()\n",
    "        \"\"\"self.model = UNet(\n",
    "                spatial_dims=2,\n",
    "                in_channels=3,\n",
    "                out_channels=3,\n",
    "                channels=(4, 8, 16,32),\n",
    "                strides=(2, 2,2),\n",
    "                num_res_units=3)\"\"\"\n",
    "        self.model = BasicUNetPlusPlus(spatial_dims =2, in_channels = 3, out_channels = 3)\n",
    "    def forward(self,x) : \n",
    "        return self.model(x)[0]\n",
    "\n",
    "    def generate_poisons(self, path = \"/home/tordjx/DATA_DIR/managed_folders/TRANSFERABLECLEANDATAPOISONING/BqfvFGr8\") : \n",
    "        files = glob.glob(os.path.join(path,\"*\"))\n",
    "        for f in files:\n",
    "            os.remove(f)\n",
    "        train_dataset_names = CustomDataset(data_dir, train=True, return_names = True)\n",
    "        train_loader_names = DataLoader(train_dataset_names, batch_size=batch_size, shuffle=True, num_workers = 19)\n",
    "        for x,y , names in train_loader_names : \n",
    "            with torch.no_grad():\n",
    "                perturb  = self.forward(x.cuda())\n",
    "                perturb = perturb.cpu()\n",
    "            for i in range(x.shape[0]):\n",
    "                poisonned = (x[i]+perturb[i]).numpy()\n",
    "                np.save(os.path.join(os.path.join(path),names[i].replace(\"ppm\",\"npy\")),poisonned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(L.LightningModule):\n",
    "    def __init__(self,generator, discriminator,train_dataloader, val_dataloader,lr = 5e-4, alpha = 1000):\n",
    "        super().__init__()\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.lr = lr\n",
    "        self.alpha = alpha\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        optimizer_g, optimizer_d = self.optimizers()\n",
    "        \n",
    "        ##DISCRIMINATOR STEP\n",
    "        with torch.no_grad():\n",
    "            perturbation = self.generator(x)\n",
    "        poisonned_image = perturbation + x\n",
    "        predictions, predicted_fakeness = self.discriminator(poisonned_image)\n",
    "        fakeness = torch.ones_like(y).cuda()\n",
    "        discriminator_loss_poisoned = torch.mean(torch.stack([self.criterion(pred,y) for pred in predictions]))\n",
    "        discriminator_loss_poisoned =discriminator_loss_poisoned+ torch.mean(torch.stack([self.criterion(pred,fakeness) for pred in predicted_fakeness]))\n",
    "        predictions, predicted_fakeness= self.discriminator(x)\n",
    "        fakeness = torch.zeros_like(y).cuda()\n",
    "\n",
    "        discriminator_loss_real = torch.mean(torch.stack([self.criterion(pred,y) for pred in predictions]))\n",
    "        discriminator_loss_real =discriminator_loss_real+ torch.mean(torch.stack([self.criterion(pred,fakeness) for pred in predicted_fakeness]))\n",
    "        discriminator_loss = discriminator_loss_poisoned+discriminator_loss_real\n",
    "        optimizer_d.zero_grad()\n",
    "        self.manual_backward(discriminator_loss)\n",
    "        optimizer_d.step()\n",
    "        self.log(\"discriminator_loss_real\", discriminator_loss_real)\n",
    "        self.log(\"discriminator_loss_poisoned\", discriminator_loss_poisoned)\n",
    "        self.log(\"discriminator_loss\", discriminator_loss)\n",
    "        ##GENERATOR STEP\n",
    "        perturbation = self.generator(x)\n",
    "        poisonned_image = perturbation + x\n",
    "        for param in self.discriminator.decoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        predictions , predicted_fakeness= self.discriminator(poisonned_image)\n",
    "        fakeness = torch.ones_like(y).cuda()\n",
    "        discriminator_loss = torch.mean(torch.stack([self.criterion(pred,y) for pred in predictions]))\n",
    "        fake_detector_loss_gen = torch.mean(torch.stack([self.criterion(pred,fakeness) for pred in predicted_fakeness]))\n",
    "        discriminator_loss =discriminator_loss + fake_detector_loss_gen\n",
    "        L2_pen = nn.MSELoss()(perturbation, torch.zeros_like(perturbation))\n",
    "        generator_loss = - discriminator_loss + self.alpha *L2_pen \n",
    "        for param in self.discriminator.decoder.parameters():\n",
    "            param.requires_grad = True\n",
    "        optimizer_g.zero_grad()\n",
    "        self.manual_backward(generator_loss, retain_graph = True)\n",
    "        optimizer_g.step()\n",
    "        self.log(\"alpha*L2_pen\", self.alpha*L2_pen)\n",
    "        self.log(\"generator_loss\", generator_loss)\n",
    "        self.log(\"fake_detector_loss_gen\", fake_detector_loss_gen)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer_G = torch.optim.Adam(self.generator.parameters(), lr=self.lr, weight_decay = 1e-4)\n",
    "        optimizer_D = torch.optim.Adam(self.discriminator.parameters(), lr=self.lr, weight_decay = 1e-4)\n",
    "        return [optimizer_G, optimizer_D], []\n",
    "\n",
    "    def on_train_epoch_start(self):\n",
    "        #Log sample image to tensorboard\n",
    "        image,y = next(iter(self.val_dataloader))\n",
    "        with torch.no_grad() : \n",
    "            perturb = self.generator(image.cuda()).cpu() \n",
    "        idx = 0\n",
    "        self.logger.experiment.add_image(\"Full perturbation\",perturb[idx].moveaxis(0,-1),self.current_epoch,dataformats=\"HWC\")\n",
    "        self.logger.experiment.add_image(\"Red perturbation\",perturb[idx][0],self.current_epoch,dataformats=\"HW\")\n",
    "        self.logger.experiment.add_image(\"Green perturbation\",perturb[idx][1],self.current_epoch,dataformats=\"HW\")\n",
    "        self.logger.experiment.add_image(\"Blue perturbation\",perturb[idx][2],self.current_epoch,dataformats=\"HW\")\n",
    "        self.logger.experiment.add_image(\"Clean image\",image[idx].moveaxis(0,-1),self.current_epoch,dataformats=\"HWC\")\n",
    "        self.logger.experiment.add_image(\"Poisoned image\",perturb[idx].moveaxis(0,-1)+image[idx].moveaxis(0,-1),self.current_epoch,dataformats=\"HWC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f4754f6d8aa0cd89\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f4754f6d8aa0cd89\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicUNetPlusPlus features: (32, 32, 64, 128, 256, 32).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tordjx/DATA_DIR/code-envs/python/rapids/lib/python3.10/site-packages/lightning/pytorch/trainer/configuration_validator.py:72: You passed in a `val_dataloader` but have no `validation_step`. Skipping val loop.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | generator     | Generator        | 2.4 M \n",
      "1 | discriminator | Discriminator    | 53.6 M\n",
      "2 | criterion     | CrossEntropyLoss | 0     \n",
      "---------------------------------------------------\n",
      "3.1 M     Trainable params\n",
      "52.9 M    Non-trainable params\n",
      "56.0 M    Total params\n",
      "224.165   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459bedd90f624519a905fdac450ea8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.environ[\"TENSORBOARD_BINARY\"]=\"/home/tordjx/DATA_DIR/code-envs/python/rapids/bin/tensorboard\"\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/\n",
    "log_name = \"5 backbones\"\n",
    "logger = TensorBoardLogger(\"lightning_logs/\", name=log_name)\n",
    "trainer = L.Trainer(max_epochs=15, logger = logger)\n",
    "encoder_names = ['resnet34' , \"resnest26d\",\"efficientnet_b0\",\"regnetx_006\",\"densenet121\"]\n",
    "generator = Generator()\n",
    "discriminator = Discriminator(encoder_names)\n",
    "gan = GAN(generator, discriminator, train_loader, test_loader)\n",
    "trainer.fit(gan, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image,y = next(iter(train_loader))\n",
    "with torch.no_grad() : \n",
    "    perturb = gan.generator.cuda()(image.cuda()).cpu() \n",
    "\n",
    "for idx in range(3):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,6, figsize = (30,5))\n",
    "    ax[0].imshow(perturb[idx].moveaxis(0,-1))\n",
    "    ax[0].set_title(\"Full perturbation\")\n",
    "    ax[1].imshow(perturb[idx][0])\n",
    "    ax[1].set_title(\"Red perturbation\")\n",
    "    ax[2].imshow(perturb[idx][1])\n",
    "    ax[2].set_title(\"Green perturbation\")\n",
    "    ax[3].imshow(perturb[idx][2])\n",
    "    ax[3].set_title(\"Blue perturbation\")\n",
    "    ax[4].imshow(image[idx].moveaxis(0,-1))\n",
    "    ax[4].set_title(\"Clean image\")\n",
    "    ax[5].imshow(perturb[idx].moveaxis(0,-1)+image[idx].moveaxis(0,-1))\n",
    "    ax[5].set_title(\"Image + perturbation\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.generator.generate_poisons()"
   ]
  }
 ],
 "metadata": {
  "createdOn": 1704122569803,
  "creator": "admin",
  "customFields": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (env rapids)",
   "language": "python",
   "name": "py-dku-venv-rapids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "modifiedBy": "admin",
  "tags": []
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
